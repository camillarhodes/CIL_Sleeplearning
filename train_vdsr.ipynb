{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfff337c",
   "metadata": {},
   "source": [
    "# Upscaling the training data using VDSR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd0a76b",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "Simply run the whole notebook. This will train the VDSR model, generate the new training data and output it to `./data/training/images_800`, `./data/training/groundtruth_800`, and `./data/test/images_800`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bca0c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pytorch_lightning import Trainer, loggers\n",
    "\n",
    "from augmentations import get_transforms\n",
    "from datasets import get_train_val_dataloaders\n",
    "from models import SegmentationModel\n",
    "\n",
    "warnings.filterwarnings(action=\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b078aa5e-4b0f-4921-8eec-89edf1880c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = get_transforms(\"rcf\")\n",
    "transform_train_512 = get_transforms(\"rcf512\")\n",
    "transform_val = get_transforms(\"center_c\")\n",
    "transform_val_512 = get_transforms(\"center_c512\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ac74d6",
   "metadata": {},
   "source": [
    "## Model creation and training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37635e0f-e4fa-44b2-bee9-f63097015bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from torch_enhance.datasets import BSDS300, Set14, Set5\n",
    "\n",
    "from torch_enhance.models import VDSR\n",
    "from torch_enhance import metrics\n",
    "\n",
    "\n",
    "class Module(pl.LightningModule):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        lr, hr = batch\n",
    "        sr = self(lr)\n",
    "        loss = F.mse_loss(sr, hr, reduction=\"mean\")\n",
    "\n",
    "        # metrics\n",
    "        mae = metrics.mae(sr, hr)\n",
    "        psnr = metrics.psnr(sr, hr)\n",
    "\n",
    "        # Logs\n",
    "        self.log(\"train_loss\", loss)\n",
    "        self.log(\"train_mae\", mae)\n",
    "        self.log(\"train_psnr\", psnr)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        lr, hr = batch\n",
    "        sr = self(lr)\n",
    "        loss = F.mse_loss(sr, hr, reduction=\"mean\")\n",
    "\n",
    "        # metrics\n",
    "        mae = metrics.mae(sr, hr)\n",
    "        psnr = metrics.psnr(sr, hr)\n",
    "\n",
    "        # Logs\n",
    "        self.log(\"val_loss\", loss)\n",
    "        self.log(\"val_mae\", mae)\n",
    "        self.log(\"val_psnr\", psnr)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        lr, hr = batch\n",
    "        sr = self(lr)\n",
    "        loss = F.mse_loss(sr, hr, reduction=\"mean\")\n",
    "\n",
    "        # metrics\n",
    "        mae = metrics.mae(sr, hr)\n",
    "        psnr = metrics.psnr(sr, hr)\n",
    "\n",
    "        # Logs\n",
    "        self.log(\"test_loss\", loss)\n",
    "        self.log(\"test_mae\", mae)\n",
    "        self.log(\"test_psnr\", psnr)\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "scale_factor = 2\n",
    "\n",
    "# Setup dataloaders\n",
    "train_dataset = BSDS300(scale_factor=scale_factor)\n",
    "val_dataset = Set14(scale_factor=scale_factor)\n",
    "test_dataset = Set5(scale_factor=scale_factor)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=1)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1)\n",
    "\n",
    "# Define model\n",
    "channels = 3 if train_dataset.color_space == \"RGB\" else 1\n",
    "model = VDSR(scale_factor, channels)\n",
    "module = Module(model)\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=60, gpus=1)\n",
    "\n",
    "trainer.fit(\n",
    "    module,\n",
    "    train_dataloader,\n",
    "    val_dataloader,\n",
    ")\n",
    "\n",
    "trainer.test(module, test_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e26f7a7-fa3e-466c-9b19-342b3e1b249b",
   "metadata": {},
   "outputs": [],
   "source": [
    "module = module.cuda()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529948b2-3d13-4fcd-8975-6b54a3a7fed3",
   "metadata": {},
   "source": [
    "## Upscaled training and test data generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21a4f57-5f58-4882-92d3-fb35030fe955",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, val_dataloader = get_train_val_dataloaders(\n",
    "    transform_train=transform_train,\n",
    "    transform_val=transform_val,\n",
    "    include_massachusetts=False,\n",
    "    num_workers=1,\n",
    "    batch_size=4,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0fa67c-45b9-43f2-8f45-189225f80e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_dir = Path(\"./data/test/images/\")\n",
    "Path(str(test_images_dir).replace(\"images\", \"images_800\")).mkdir(exist_ok=True)\n",
    "test_paths = list(test_images_dir.glob(\"*.png\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1764035b-f863-403b-b688-650e6b8a8b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(\n",
    "    str(train_dataloader.dataset.img_files[0].parent).replace(\"images\", \"images_800\")\n",
    ").mkdir(exist_ok=True)\n",
    "Path(\n",
    "    str(train_dataloader.dataset.mask_files[0].parent).replace(\n",
    "        \"groundtruth\", \"groundtruth_800\"\n",
    "    )\n",
    ").mkdir(exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a8bdc6-fe78-4145-b34a-b2ffbf102faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_path in test_paths:\n",
    "    img_np = cv2.imread(str(test_path))\n",
    "    img_tensor = torch.Tensor(img_np[None, :].transpose(0, 3, 1, 2)).to(module.device)\n",
    "    img_tensor_big = module(img_tensor)\n",
    "    fname_out = str(Path(str(test_path).replace(\"images\", \"images_800\")))\n",
    "    cv2.imwrite(fname_out, img_tensor_big[0].detach().cpu().numpy().transpose(1, 2, 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f833f25-b6f6-487e-b165-df8bcb50b6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_path in train_dataloader.dataset.img_files + val_dataloader.dataset.img_files:\n",
    "    img_np = cv2.imread(str(train_path))\n",
    "    img_tensor = torch.Tensor(img_np[None, :].transpose(0, 3, 1, 2)).to(module.device)\n",
    "    img_tensor_big = module(img_tensor)\n",
    "    fname_out = str(Path(str(train_path).replace(\"images\", \"images_800\")))\n",
    "    cv2.imwrite(fname_out, img_tensor_big[0].detach().cpu().numpy().transpose(1, 2, 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce964ca1-eec1-471e-8f5d-c2d02f859541",
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_mask_path in (\n",
    "    train_dataloader.dataset.mask_files + val_dataloader.dataset.mask_files\n",
    "):\n",
    "    img_np = cv2.imread(str(train_mask_path))\n",
    "    img_np_big = cv2.resize(img_np, (800, 800), interpolation=cv2.INTER_AREA)\n",
    "    fname_out = str(\n",
    "        Path(str(train_mask_path).replace(\"groundtruth\", \"groundtruth_800\"))\n",
    "    )\n",
    "    cv2.imwrite(fname_out, img_np_big)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('CIL_Sleeplearning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "6c86dc6fb6756744c52c6c4c120a0f147cc85e4ec7798bcdbc0540d80120a0a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
