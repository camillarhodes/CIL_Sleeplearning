{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bca0c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import args\n",
    "from pytorch_lightning import Trainer, loggers\n",
    "from models import SegmentationModel\n",
    "from augmentations import get_transforms\n",
    "from datasets import get_train_val_dataloaders\n",
    "import warnings \n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "warnings.filterwarnings(action= 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b078aa5e-4b0f-4921-8eec-89edf1880c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train=get_transforms('rcf')\n",
    "transform_train_512=get_transforms('rcf512')\n",
    "transform_val=get_transforms('center_c')\n",
    "transform_val_512=get_transforms('center_c512')\n",
    "\n",
    "\n",
    "# transform_train_sm=get_transforms('rcr128')\n",
    "# transform_val_sm=get_transforms('center_cr128')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37635e0f-e4fa-44b2-bee9-f63097015bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | VDSR | 668 K \n",
      "-------------------------------\n",
      "668 K     Trainable params\n",
      "0         Non-trainable params\n",
      "668 K     Total params\n",
      "2.673     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b63c7d990c4a4d418a3c2e96bbaae3ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce693813e0cc4ff9a4ab7b371866da90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss          0.0009362331475131214\n",
      "        test_mae           0.019659385085105896\n",
      "        test_psnr           31.275863647460938\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.0009362331475131214,\n",
       "  'test_mae': 0.019659385085105896,\n",
       "  'test_psnr': 31.275863647460938}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from torch_enhance.datasets import BSDS300, Set14, Set5\n",
    "from torch_enhance.models import SRCNN, SRResNet, VDSR, EDSR\n",
    "from torch_enhance import metrics\n",
    "\n",
    "\n",
    "class Module(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        lr, hr = batch\n",
    "        sr = self(lr)\n",
    "        loss = F.mse_loss(sr, hr, reduction=\"mean\")\n",
    "        \n",
    "        # metrics\n",
    "        mae = metrics.mae(sr, hr)\n",
    "        psnr = metrics.psnr(sr, hr)\n",
    "\n",
    "        # Logs\n",
    "        self.log(\"train_loss\", loss)\n",
    "        self.log(\"train_mae\", mae)\n",
    "        self.log(\"train_psnr\", psnr)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        lr, hr = batch\n",
    "        sr = self(lr)\n",
    "        loss = F.mse_loss(sr, hr, reduction=\"mean\")\n",
    "        \n",
    "        # metrics\n",
    "        mae = metrics.mae(sr, hr)\n",
    "        psnr = metrics.psnr(sr, hr)\n",
    "\n",
    "        # Logs\n",
    "        self.log(\"val_loss\", loss)\n",
    "        self.log(\"val_mae\", mae)\n",
    "        self.log(\"val_psnr\", psnr)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        lr, hr = batch\n",
    "        sr = self(lr)\n",
    "        loss = F.mse_loss(sr, hr, reduction=\"mean\")\n",
    "        \n",
    "        # metrics\n",
    "        mae = metrics.mae(sr, hr)\n",
    "        psnr = metrics.psnr(sr, hr)\n",
    "\n",
    "        # Logs\n",
    "        self.log(\"test_loss\", loss)\n",
    "        self.log(\"test_mae\", mae)\n",
    "        self.log(\"test_psnr\", psnr)\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "scale_factor = 2\n",
    "\n",
    "# Setup dataloaders\n",
    "train_dataset = BSDS300(scale_factor=scale_factor)\n",
    "val_dataset = Set14(scale_factor=scale_factor)\n",
    "test_dataset = Set5(scale_factor=scale_factor)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=1)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1)\n",
    "\n",
    "# Define model\n",
    "channels = 3 if train_dataset.color_space == \"RGB\" else 1\n",
    "model = VDSR(scale_factor, channels)\n",
    "# model = SRResNet(scale_factor, channels)\n",
    "module = Module(model)\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=60, gpus=4,accelerator='dp')\n",
    "trainer.fit(\n",
    "    module,\n",
    "    train_dataloader,\n",
    "    val_dataloader,\n",
    ") \n",
    "\n",
    "trainer.test(module, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e26f7a7-fa3e-466c-9b19-342b3e1b249b",
   "metadata": {},
   "outputs": [],
   "source": [
    "module = module.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529948b2-3d13-4fcd-8975-6b54a3a7fed3",
   "metadata": {},
   "source": [
    "# Make directories for SR (large) images and save them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f21a4f57-5f58-4882-92d3-fb35030fe955",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, val_dataloader = get_train_val_dataloaders(\n",
    "    transform_train=transform_train, transform_val=transform_val,\n",
    "    include_massachusetts=False,\n",
    "    num_workers=8,\n",
    "    batch_size=4,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf0fa67c-45b9-43f2-8f45-189225f80e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_dir = Path('./data/test/images/')\n",
    "test_paths = list(test_images_dir.glob('*.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1764035b-f863-403b-b688-650e6b8a8b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path(str(test_images_dir).replace('images','images_800')).mkdir(exist_ok=True)\n",
    "Path(str(train_dataloader.dataset.img_files[0].parent).replace('images','images_800')).mkdir(exist_ok=True)\n",
    "Path(str(train_dataloader.dataset.mask_files[0].parent).replace('groundtruth','groundtruth_800')).mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a8bdc6-fe78-4145-b34a-b2ffbf102faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_path in test_paths:\n",
    "    img_np = cv2.imread(str(test_path))\n",
    "    img_tensor=torch.Tensor(img_np[None,:].transpose(0,3,1,2)).to(module.device)\n",
    "    img_tensor_big = module(img_tensor)\n",
    "    fname_out = str(Path(str(test_path).replace('images','images_800')))\n",
    "    cv2.imwrite(fname_out,img_tensor_big[0].detach().cpu().numpy().transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3f833f25-b6f6-487e-b165-df8bcb50b6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_path in train_dataloader.dataset.img_files+val_dataloader.dataset.img_files:\n",
    "    img_np = cv2.imread(str(train_path))\n",
    "    img_tensor=torch.Tensor(img_np[None,:].transpose(0,3,1,2)).to(module.device)\n",
    "    img_tensor_big = module(img_tensor)\n",
    "    fname_out = str(Path(str(train_path).replace('images','images_800_bla')))\n",
    "    cv2.imwrite(fname_out,img_tensor_big[0].detach().cpu().numpy().transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "ce964ca1-eec1-471e-8f5d-c2d02f859541",
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_mask_path in train_dataloader.dataset.mask_files+val_dataloader.dataset.mask_files:\n",
    "    img_np = cv2.imread(str(train_mask_path))\n",
    "    img_np_big=cv2.resize(img_np, (800,800), interpolation=cv2.INTER_AREA)\n",
    "    fname_out = str(Path(str(train_mask_path).replace('groundtruth','groundtruth_800')))\n",
    "    cv2.imwrite(fname_out,img_np_big)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3097d602-5424-4887-8380-e5cb8bbefe64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
