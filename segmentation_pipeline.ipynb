{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-Lab-MS segmentation pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "from config import args\n",
    "import torch\n",
    "from pytorch_lightning import Trainer, loggers\n",
    "from models import SegmentationModel\n",
    "from augmentations import get_transforms\n",
    "from datasets import get_train_val_dataloaders\n",
    "import warnings\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "warnings.filterwarnings(action='ignore')\n",
    "from segmentation_models_pytorch.losses import DiceLoss\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trainer(name):\n",
    "    tb_logger = loggers.TensorBoardLogger(save_dir=\"logs/\", name=name)\n",
    "    trainer = Trainer(gpus=1,\n",
    "                  max_epochs=200, \n",
    "                  logger=tb_logger,\n",
    "                #   accelerator='ddp',\n",
    "                  resume_from_checkpoint=args.checkpoint_path,\n",
    "                  log_every_n_steps=10\n",
    "    )\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trained_model(name, model_type, transform_type, encoder_weights, upscaling):\n",
    "    transform_train = None\n",
    "    if transform_type is not None:\n",
    "        transform_train = get_transforms(transform_type)\n",
    "\n",
    "    train_dataloader_full, _ = get_train_val_dataloaders(\n",
    "        split_percent=1.00,\n",
    "        transform_train=transform_train, transform_val=None,\n",
    "        include_massachusetts=False,\n",
    "        num_workers=0,\n",
    "        batch_size=4,\n",
    "        upscaling=upscaling\n",
    "    )\n",
    "    print(len(train_dataloader_full), model_type, transform_type, encoder_weights, upscaling)\n",
    "    model = SegmentationModel(model_type, encoder_weights)\n",
    "    trainer = get_trainer(name)\n",
    "    trainer.fit(model, train_dataloader_full)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predicted_masks(model, name, upscaling):\n",
    "    idx = 0\n",
    "    predictions_dir = Path(f'./data/test/{name}/')\n",
    "    if upscaling == \"vdsr\":\n",
    "        test_images_dir = Path('./data/test/images_800/')\n",
    "    else:\n",
    "        test_images_dir = Path('./data/test/images/')\n",
    "    \n",
    "    test_paths = list(test_images_dir.glob('*.png'))\n",
    "    predictions_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    for img_path in test_paths:\n",
    "        print(f'{idx}/{len(test_paths)}')\n",
    "        idx += 1\n",
    "        img = cv2.imread(str(img_path))\n",
    "        img = (img.transpose(2,0,1) / 255).astype(np.float32)[None,:]\n",
    "    \n",
    "        pred_mask = model.predict_full_mask(img).cpu().numpy()[0]\n",
    "        \n",
    "        cv2.imwrite(str(predictions_dir / img_path.stem) + '.png',255*pred_mask.transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ensemble_predicted_masks(models, name, upscaling_array):\n",
    "    idx = 0\n",
    "    predictions_dir = Path(f'./data/test/{name}/')\n",
    "    test_images_dir = Path('./data/test/images/')\n",
    "    test_images_800_dir = Path('./data/test/images_800/')\n",
    "    \n",
    "    test_paths = list(test_images_dir.glob('*.png'))\n",
    "    test_800_paths = list(test_images_800_dir.glob('*.png'))\n",
    "    predictions_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    for img_path, img_800_path in zip(test_paths, test_800_paths):\n",
    "        print(f'{idx}/{len(test_paths)}')\n",
    "        idx += 1\n",
    "        pred_mask = None\n",
    "        for model, upscaling in zip(models, upscaling_array):\n",
    "            if upscaling == \"vdsr\":\n",
    "                img = cv2.imread(str(img_800_path))\n",
    "            else:\n",
    "                img = cv2.imread(str(img_path))\n",
    "            img = (img.transpose(2,0,1) / 255).astype(np.float32)[None,:]\n",
    "\n",
    "            prediction = model.predict_full_mask(img).cpu().numpy()[0]\n",
    "            if pred_mask is None:\n",
    "                pred_mask = prediction\n",
    "            else:\n",
    "                pred_mask += prediction\n",
    "\n",
    "        pred_mask /= len(models)\n",
    "        cv2.imwrite(str(predictions_dir / img_path.stem) + '.png',255*pred_mask.transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segmentation_models_pytorch.losses import DiceLoss\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def evaluate_ensemble(models, upscaling_array):\n",
    "    idx = 0\n",
    "    train_images_dir = Path('./data/training/images/')\n",
    "    train_images_800_dir = Path('./data/training/images_800/')\n",
    "\n",
    "    mask_images_dir = Path('./data/training/groundtruth/')\n",
    "    \n",
    "    train_paths = list(train_images_dir.glob('*.png'))\n",
    "    train_800_paths = list(train_images_800_dir.glob('*.png'))\n",
    "\n",
    "    mask_paths = list(mask_images_dir.glob('*.png'))\n",
    "\n",
    "    dice_evals = []\n",
    "    f1_evals = []\n",
    "\n",
    "    dice = DiceLoss('binary', from_logits=False)\n",
    "\n",
    "    for img_path, img_800_path, mask_path in zip(train_paths, train_800_paths, mask_paths):\n",
    "        print(f'{idx}/{len(train_paths)}')\n",
    "        idx += 1\n",
    "\n",
    "        pred_mask = None\n",
    "        for model, upscaling in zip(models, upscaling_array):\n",
    "            if upscaling == \"vdsr\":\n",
    "                img = cv2.imread(str(img_800_path))\n",
    "            else:\n",
    "                img = cv2.imread(str(img_path))\n",
    "            img = (img.transpose(2,0,1) / 255).astype(np.float32)[None,:]\n",
    "\n",
    "            if pred_mask is None:\n",
    "                pred_mask = model.predict_full_mask(img).cpu().numpy()[0]\n",
    "            else:\n",
    "                pred_mask += model.predict_full_mask(img).cpu().numpy()[0]\n",
    "\n",
    "        pred_mask /= len(models)\n",
    "\n",
    "        pred_mask = torch.from_numpy(pred_mask.reshape(1,1,400,400))\n",
    "\n",
    "        mask = cv2.imread(str(mask_path))\n",
    "        mask = (mask[:,:,:1].transpose(2,0,1) / 255).astype(np.float32)\n",
    "        labels = torch.from_numpy(mask.reshape(1,400,400)).int().long()\n",
    "\n",
    "        pred_mask[pred_mask >= 0.25] = 1\n",
    "        pred_mask[pred_mask < 0.25] = 0\n",
    "\n",
    "        dice_eval = dice(pred_mask, labels)\n",
    "        dice_eval = dice_eval.data.cpu().numpy()\n",
    "        dice_evals.append(dice_eval)\n",
    "                \n",
    "        f1_eval = f1_score(pred_mask.reshape(-1), labels.reshape(-1))\n",
    "        print(dice_eval, f1_eval)\n",
    "        f1_evals.append(f1_eval)\n",
    "    \n",
    "    print(f\"Training Dice loss: {sum(dice_evals) / len(dice_evals)}\")\n",
    "    print(f\"Training F1 score: {sum(f1_evals) / len(f1_evals)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_submission_file(name):\n",
    "    submission_path = Path(\"./kaggle_submissions\")\n",
    "    submission_path.mkdir(exist_ok=True)\n",
    "    cmd = f'python ./data/mask_to_submission.py --submission_filename=\"{submission_path / name}.csv\" --base_dir=\"./data/test/{name}/\"'\n",
    "    subprocess.call(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_model_pipeline(name, model_type, transform_type, encoder_weights, upscaling):\n",
    "    model = get_trained_model(name, model_type, transform_type, encoder_weights, upscaling)\n",
    "    generate_predicted_masks(model, name, upscaling)\n",
    "    generate_submission_file(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_trained_model_pipeline(name, checkpoint_dir, model_type, upscaling):\n",
    "    model = SegmentationModel.load_from_checkpoint(checkpoint_dir, seg_model=model_type)\n",
    "    generate_predicted_masks(model, name, upscaling)\n",
    "    generate_submission_file(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_ensemble_pipeline(ensemble_name, model_names, model_types, transform_type_array, encoder_weights_array, upscaling_array):\n",
    "    models = [\n",
    "        get_trained_model(*params) for params in zip(model_names, model_types, transform_type_array, encoder_weights_array, upscaling_array)]\n",
    "    generate_ensemble_predicted_masks(models, ensemble_name, upscaling_array)\n",
    "    generate_submission_file(ensemble_name)\n",
    "    evaluate_ensemble(models, upscaling_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_trained_ensemble_pipeline(ensemble_name, checkpoint_paths, model_types, upscaling_array):\n",
    "    models = [\n",
    "        SegmentationModel.load_from_checkpoint(checkpoint_path, seg_model=model_type) for checkpoint_path, model_type in zip(checkpoint_paths, model_types)]\n",
    "    generate_ensemble_predicted_masks(models, ensemble_name, upscaling_array)\n",
    "    generate_submission_file(ensemble_name)\n",
    "    evaluate_ensemble(models, upscaling_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_ensemble_eval_pipeline(checkpoint_paths, model_types, upscaling_array):\n",
    "    models = [\n",
    "        SegmentationModel.load_from_checkpoint(checkpoint_path, seg_model=model_type) for checkpoint_path, model_type in zip(checkpoint_paths, model_types)]\n",
    "    return evaluate_ensemble(models, upscaling_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U-Lab-MS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_ensemble_pipeline(\n",
    "    ensemble_name=\"U-Lab-MS\",\n",
    "    model_names=[\"U-lab-MS-U-Net-Small\", \"U-lab-MS-DeepLabV3Plus-Small\", \"U-lab-MS-U-Net-Big\", \"U-lab-MS-DeepLabV3Plus-Big\"],\n",
    "    model_types=[\"unet\", \"deeplabv3plus\", \"unet\", \"deeplabv3plus\"],\n",
    "    transform_type_array=['rcf', 'rcf', 'rcf512', 'rcf512'],\n",
    "    encoder_weights_array=[\"imagenet\", \"imagenet\", \"imagenet\", \"imagenet\"],\n",
    "    upscaling_array=[None, None, \"vdsr\", \"vdsr\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models used for ablation studies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### U-Net256 (-A, -P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "perform_model_pipeline(name=\"unet_small_no_augmentations_not_pretrained\", \n",
    "                       model_type=\"unet\",\n",
    "                       transform_type='resize_384',\n",
    "                       encoder_weights=None,\n",
    "                       upscaling=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### U-Net256 (-A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "perform_model_pipeline(name=\"unet_small_no_augmentations_pretrained\", \n",
    "                       model_type=\"unet\",\n",
    "                       transform_type='resize_384',\n",
    "                       encoder_weights='imagenet',\n",
    "                       upscaling=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### U-Net256 (-P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "perform_model_pipeline(name=\"unet_small_with_augmentations_not_pretrained\", \n",
    "                       model_type=\"unet\",\n",
    "                       transform_type='rcf',\n",
    "                       encoder_weights=None,\n",
    "                       upscaling=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### U-Net256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "perform_model_pipeline(name=\"unet_small_with_augmentations_pretrained\", \n",
    "                       model_type=\"unet\",\n",
    "                       transform_type='rcf',\n",
    "                       encoder_weights='imagenet',\n",
    "                       upscaling=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### U-Net-ASPP256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeepLabV3Plus256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "perform_model_pipeline(name=\"deeplab_small_with_augmentations_pretrained\", \n",
    "                       model_type=\"deeplabv3plus\",\n",
    "                       transform_type='rcf',\n",
    "                       encoder_weights='imagenet',\n",
    "                       upscaling=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### U-Net-512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "perform_model_pipeline(name=\"unet_big_with_augmentations_pretrained\", \n",
    "                       model_type=\"unet\",\n",
    "                       transform_type='rcf512',\n",
    "                       encoder_weights='imagenet',\n",
    "                       upscaling='vdsr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeepLabV3Plus512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "perform_model_pipeline(name=\"deeplab_big_with_augmentations_pretrained\", \n",
    "                       model_type=\"deeplabv3plus\",\n",
    "                       transform_type='rcf512',\n",
    "                       encoder_weights='imagenet',\n",
    "                       upscaling='vdsr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### U-Net-Edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### U-Lab-256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_ensemble_pipeline(\n",
    "    ensemble_name=\"U-Lab-small\",\n",
    "    model_names=[\"U-lab-small-U-Net-Small\", \"U-lab-small-DeepLabV3Plus-Small\"],\n",
    "    model_types=[\"unet\", \"deeplabv3plus\"],\n",
    "    transform_type_array=['rcf', 'rcf'],\n",
    "    encoder_weights_array=[\"imagenet\", \"imagenet\"],\n",
    "    upscaling_array=[None, None]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### U-Lab-512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_ensemble_pipeline(\n",
    "    ensemble_name=\"U-Lab-big\",\n",
    "    model_names=[\"U-lab-big-U-Net-Big\", \"U-lab-big-DeepLabV3Plus-Big\"],\n",
    "    model_types=[\"unet\", \"deeplabv3plus\"],\n",
    "    transform_type_array=['rcf512', 'rcf512'],\n",
    "    encoder_weights_array=[\"imagenet\", \"imagenet\"],\n",
    "    upscaling_array=[\"vdsr\", \"vdsr\"]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('CIL_Sleeplearning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6c86dc6fb6756744c52c6c4c120a0f147cc85e4ec7798bcdbc0540d80120a0a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
