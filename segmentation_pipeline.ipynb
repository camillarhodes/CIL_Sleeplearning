{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-Lab-MS segmentation pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "import subprocess\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from pytorch_lightning import Trainer, loggers\n",
    "\n",
    "from augmentations import get_transforms\n",
    "from datasets import get_train_val_dataloaders\n",
    "from models import SegmentationModel\n",
    "\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "from segmentation_models_pytorch.losses import DiceLoss\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trainer(name):\n",
    "    tb_logger = loggers.TensorBoardLogger(save_dir=\"logs/\", name=name)\n",
    "    trainer = Trainer(\n",
    "        auto_select_gpus=True,\n",
    "        accelerator=\"auto\",\n",
    "        max_epochs=200,\n",
    "        logger=tb_logger,\n",
    "        log_every_n_steps=10,\n",
    "    )\n",
    "    return trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trained_model(name, model_type, transform_type, encoder_weights, upscaling):\n",
    "    transform_train = None\n",
    "    if transform_type is not None:\n",
    "        transform_train = get_transforms(transform_type)\n",
    "\n",
    "    train_dataloader_full, _ = get_train_val_dataloaders(\n",
    "        split_percent=1.00,\n",
    "        transform_train=transform_train,\n",
    "        transform_val=None,\n",
    "        include_massachusetts=False,\n",
    "        num_workers=0,\n",
    "        batch_size=4,\n",
    "        upscaling=upscaling,\n",
    "    )\n",
    "    model = SegmentationModel(model_type, encoder_weights)\n",
    "    trainer = get_trainer(name)\n",
    "    trainer.fit(model, train_dataloader_full)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predicted_masks(model, name, upscaling):\n",
    "    idx = 0\n",
    "    predictions_dir = Path(f\"./data/test/{name}/\")\n",
    "    if upscaling == \"vdsr\":\n",
    "        test_images_dir = Path(\"./data/test/images_800/\")\n",
    "    else:\n",
    "        test_images_dir = Path(\"./data/test/images/\")\n",
    "\n",
    "    test_paths = list(test_images_dir.glob(\"*.png\"))\n",
    "    predictions_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    for img_path in test_paths:\n",
    "        print(f\"{idx}/{len(test_paths)}\")\n",
    "        idx += 1\n",
    "        img = cv2.imread(str(img_path))\n",
    "        img = (img.transpose(2, 0, 1) / 255).astype(np.float32)[None, :]\n",
    "\n",
    "        pred_mask = model.predict_full_mask(img).cpu().numpy()[0]\n",
    "\n",
    "        cv2.imwrite(\n",
    "            str(predictions_dir / img_path.stem) + \".png\",\n",
    "            255 * pred_mask.transpose(1, 2, 0),\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ensemble_predicted_masks(models, name, upscaling_array):\n",
    "    idx = 0\n",
    "    predictions_dir = Path(f\"./data/test/{name}/\")\n",
    "    test_images_dir = Path(\"./data/test/images/\")\n",
    "    test_images_800_dir = Path(\"./data/test/images_800/\")\n",
    "\n",
    "    test_paths = list(test_images_dir.glob(\"*.png\"))\n",
    "    test_800_paths = list(test_images_800_dir.glob(\"*.png\"))\n",
    "    predictions_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    for img_path, img_800_path in zip(test_paths, test_800_paths):\n",
    "        print(f\"{idx}/{len(test_paths)}\")\n",
    "        idx += 1\n",
    "        pred_mask = None\n",
    "        for model, upscaling in zip(models, upscaling_array):\n",
    "            if upscaling == \"vdsr\":\n",
    "                img = cv2.imread(str(img_800_path))\n",
    "            else:\n",
    "                img = cv2.imread(str(img_path))\n",
    "            img = (img.transpose(2, 0, 1) / 255).astype(np.float32)[None, :]\n",
    "\n",
    "            prediction = model.predict_full_mask(img).cpu().numpy()[0]\n",
    "            if pred_mask is None:\n",
    "                pred_mask = prediction\n",
    "            else:\n",
    "                pred_mask += prediction\n",
    "\n",
    "        pred_mask /= len(models)\n",
    "        cv2.imwrite(\n",
    "            str(predictions_dir / img_path.stem) + \".png\",\n",
    "            255 * pred_mask.transpose(1, 2, 0),\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_ensemble(models, upscaling_array):\n",
    "    idx = 0\n",
    "    train_images_dir = Path(\"./data/training/images/\")\n",
    "    train_images_800_dir = Path(\"./data/training/images_800/\")\n",
    "\n",
    "    mask_images_dir = Path(\"./data/training/groundtruth/\")\n",
    "\n",
    "    train_paths = list(train_images_dir.glob(\"*.png\"))\n",
    "    train_800_paths = list(train_images_800_dir.glob(\"*.png\"))\n",
    "\n",
    "    mask_paths = list(mask_images_dir.glob(\"*.png\"))\n",
    "\n",
    "    dice_evals = []\n",
    "    f1_evals = []\n",
    "\n",
    "    dice = DiceLoss(\"binary\", from_logits=False)\n",
    "\n",
    "    for img_path, img_800_path, mask_path in zip(\n",
    "        train_paths, train_800_paths, mask_paths\n",
    "    ):\n",
    "        print(f\"{idx}/{len(train_paths)}\")\n",
    "        idx += 1\n",
    "\n",
    "        pred_mask = None\n",
    "        for model, upscaling in zip(models, upscaling_array):\n",
    "            if upscaling == \"vdsr\":\n",
    "                img = cv2.imread(str(img_800_path))\n",
    "            else:\n",
    "                img = cv2.imread(str(img_path))\n",
    "            img = (img.transpose(2, 0, 1) / 255).astype(np.float32)[None, :]\n",
    "\n",
    "            if pred_mask is None:\n",
    "                pred_mask = model.predict_full_mask(img).cpu().numpy()[0]\n",
    "            else:\n",
    "                pred_mask += model.predict_full_mask(img).cpu().numpy()[0]\n",
    "\n",
    "        pred_mask /= len(models)\n",
    "\n",
    "        pred_mask = torch.from_numpy(pred_mask.reshape(1, 1, 400, 400))\n",
    "\n",
    "        mask = cv2.imread(str(mask_path))\n",
    "        mask = (mask[:, :, :1].transpose(2, 0, 1) / 255).astype(np.float32)\n",
    "        labels = torch.from_numpy(mask.reshape(1, 400, 400)).int().long()\n",
    "\n",
    "        pred_mask[pred_mask >= 0.25] = 1\n",
    "        pred_mask[pred_mask < 0.25] = 0\n",
    "\n",
    "        dice_eval = dice(pred_mask, labels)\n",
    "        dice_eval = dice_eval.data.cpu().numpy()\n",
    "        dice_evals.append(dice_eval)\n",
    "\n",
    "        f1_eval = f1_score(pred_mask.reshape(-1), labels.reshape(-1))\n",
    "        print(dice_eval, f1_eval)\n",
    "        f1_evals.append(f1_eval)\n",
    "\n",
    "    print(f\"Training Dice loss: {sum(dice_evals) / len(dice_evals)}\")\n",
    "    print(f\"Training F1 score: {sum(f1_evals) / len(f1_evals)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_submission_file(name):\n",
    "    submission_path = Path(\"./kaggle_submissions\")\n",
    "    submission_path.mkdir(exist_ok=True)\n",
    "    cmd = f'python ./data/mask_to_submission.py --submission_filename=\"{submission_path / name}.csv\" --base_dir=\"./data/test/{name}/\"'\n",
    "    subprocess.call(cmd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_model_pipeline(\n",
    "    name, model_type, transform_type, encoder_weights, upscaling\n",
    "):\n",
    "    model = get_trained_model(\n",
    "        name, model_type, transform_type, encoder_weights, upscaling\n",
    "    )\n",
    "    generate_predicted_masks(model, name, upscaling)\n",
    "    generate_submission_file(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_trained_model_pipeline(name, checkpoint_dir, model_type, upscaling):\n",
    "    model = SegmentationModel.load_from_checkpoint(checkpoint_dir, seg_model=model_type)\n",
    "    generate_predicted_masks(model, name, upscaling)\n",
    "    generate_submission_file(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_ensemble_pipeline(\n",
    "    ensemble_name,\n",
    "    model_names,\n",
    "    model_types,\n",
    "    transform_type_array,\n",
    "    encoder_weights_array,\n",
    "    upscaling_array,\n",
    "):\n",
    "    models = [\n",
    "        get_trained_model(*params)\n",
    "        for params in zip(\n",
    "            model_names,\n",
    "            model_types,\n",
    "            transform_type_array,\n",
    "            encoder_weights_array,\n",
    "            upscaling_array,\n",
    "        )\n",
    "    ]\n",
    "    generate_ensemble_predicted_masks(models, ensemble_name, upscaling_array)\n",
    "    generate_submission_file(ensemble_name)\n",
    "    evaluate_ensemble(models, upscaling_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_trained_ensemble_pipeline(\n",
    "    ensemble_name, checkpoint_paths, model_types, upscaling_array\n",
    "):\n",
    "    models = [\n",
    "        SegmentationModel.load_from_checkpoint(checkpoint_path, seg_model=model_type)\n",
    "        for checkpoint_path, model_type in zip(checkpoint_paths, model_types)\n",
    "    ]\n",
    "    generate_ensemble_predicted_masks(models, ensemble_name, upscaling_array)\n",
    "    generate_submission_file(ensemble_name)\n",
    "    evaluate_ensemble(models, upscaling_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_ensemble_eval_pipeline(checkpoint_paths, model_types, upscaling_array):\n",
    "    models = [\n",
    "        SegmentationModel.load_from_checkpoint(checkpoint_path, seg_model=model_type)\n",
    "        for checkpoint_path, model_type in zip(checkpoint_paths, model_types)\n",
    "    ]\n",
    "    return evaluate_ensemble(models, upscaling_array)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U-Lab-MS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_ensemble_pipeline(\n",
    "    ensemble_name=\"U-Lab-MS\",\n",
    "    model_names=[\n",
    "        \"U-lab-MS-U-Net-Small\",\n",
    "        \"U-lab-MS-DeepLabV3Plus-Small\",\n",
    "        \"U-lab-MS-U-Net-Big\",\n",
    "        \"U-lab-MS-DeepLabV3Plus-Big\",\n",
    "    ],\n",
    "    model_types=[\"unet\", \"deeplabv3plus\", \"unet\", \"deeplabv3plus\"],\n",
    "    transform_type_array=[\"rcf\", \"rcf\", \"rcf512\", \"rcf512\"],\n",
    "    encoder_weights_array=[\"imagenet\", \"imagenet\", \"imagenet\", \"imagenet\"],\n",
    "    upscaling_array=[None, None, \"vdsr\", \"vdsr\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models used for ablation studies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### U-Net256 (-A, -P)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "perform_model_pipeline(\n",
    "    name=\"unet_small_no_augmentations_not_pretrained\",\n",
    "    model_type=\"unet\",\n",
    "    transform_type=\"resize_384\",\n",
    "    encoder_weights=None,\n",
    "    upscaling=None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### U-Net256 (-A)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "perform_model_pipeline(\n",
    "    name=\"unet_small_no_augmentations_pretrained\",\n",
    "    model_type=\"unet\",\n",
    "    transform_type=\"resize_384\",\n",
    "    encoder_weights=\"imagenet\",\n",
    "    upscaling=None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### U-Net256 (-P)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "perform_model_pipeline(\n",
    "    name=\"unet_small_with_augmentations_not_pretrained\",\n",
    "    model_type=\"unet\",\n",
    "    transform_type=\"rcf\",\n",
    "    encoder_weights=None,\n",
    "    upscaling=None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### U-Net256\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "perform_model_pipeline(\n",
    "    name=\"unet_small_with_augmentations_pretrained\",\n",
    "    model_type=\"unet\",\n",
    "    transform_type=\"rcf\",\n",
    "    encoder_weights=\"imagenet\",\n",
    "    upscaling=None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### U-Net-ASPP256\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "perform_model_pipeline(\n",
    "    name=\"unet_aspp\",\n",
    "    model_type=\"unet\",\n",
    "    transform_type=\"rcf\",\n",
    "    encoder_weights=None,\n",
    "    upscaling=None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeepLabV3Plus256\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "perform_model_pipeline(\n",
    "    name=\"deeplab_small_with_augmentations_pretrained\",\n",
    "    model_type=\"deeplabv3plus\",\n",
    "    transform_type=\"rcf\",\n",
    "    encoder_weights=\"imagenet\",\n",
    "    upscaling=None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### U-Net-512\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "perform_model_pipeline(\n",
    "    name=\"unet_big_with_augmentations_pretrained\",\n",
    "    model_type=\"unet\",\n",
    "    transform_type=\"rcf512\",\n",
    "    encoder_weights=\"imagenet\",\n",
    "    upscaling=\"vdsr\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeepLabV3Plus512\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "perform_model_pipeline(\n",
    "    name=\"deeplab_big_with_augmentations_pretrained\",\n",
    "    model_type=\"deeplabv3plus\",\n",
    "    transform_type=\"rcf512\",\n",
    "    encoder_weights=\"imagenet\",\n",
    "    upscaling=\"vdsr\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### U-Net-Edge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "perform_model_pipeline(\n",
    "    name=\"unet-edge\",\n",
    "    model_type=\"edgemap_fused_unet\",\n",
    "    transform_type=\"rcf\",\n",
    "    encoder_weights=\"imagenet\",\n",
    "    upscaling=None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### U-Lab-256\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_ensemble_pipeline(\n",
    "    ensemble_name=\"U-Lab-small\",\n",
    "    model_names=[\"U-lab-small-U-Net-Small\", \"U-lab-small-DeepLabV3Plus-Small\"],\n",
    "    model_types=[\"unet\", \"deeplabv3plus\"],\n",
    "    transform_type_array=[\"rcf\", \"rcf\"],\n",
    "    encoder_weights_array=[\"imagenet\", \"imagenet\"],\n",
    "    upscaling_array=[None, None],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### U-Lab-512\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_ensemble_pipeline(\n",
    "    ensemble_name=\"U-Lab-big\",\n",
    "    model_names=[\"U-lab-big-U-Net-Big\", \"U-lab-big-DeepLabV3Plus-Big\"],\n",
    "    model_types=[\"unet\", \"deeplabv3plus\"],\n",
    "    transform_type_array=[\"rcf512\", \"rcf512\"],\n",
    "    encoder_weights_array=[\"imagenet\", \"imagenet\"],\n",
    "    upscaling_array=[\"vdsr\", \"vdsr\"],\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('CIL_Sleeplearning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6c86dc6fb6756744c52c6c4c120a0f147cc85e4ec7798bcdbc0540d80120a0a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
