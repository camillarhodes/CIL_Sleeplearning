{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e1520be-fb38-4c33-8986-9bced70602e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import args\n",
    "from pytorch_lightning import Trainer, loggers\n",
    "from models import get_pl_model\n",
    "from augmentations import get_transforms\n",
    "from datasets import get_train_val_dataloaders\n",
    "import warnings \n",
    "warnings.filterwarnings(action= 'ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c0f00d-09b5-498f-8387-2d08c5369b70",
   "metadata": {},
   "source": [
    "# Get augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2db79a60-42ab-4a96-95f4-5c1c655f72ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform_train=get_transforms('cf')\n",
    "transform_train=get_transforms('cfc')\n",
    "transform_val=get_transforms('r256')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d98e88b-d52c-4d5a-b744-acf561c7e9ee",
   "metadata": {},
   "source": [
    "# Get data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c50278a-a7bc-42d2-a293-8a57ccd7a940",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, val_dataloader = get_train_val_dataloaders(transform_train=transform_train, transform_val=transform_val, include_massachusetts=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84457931-78af-4c37-96ea-55508b07f2d1",
   "metadata": {},
   "source": [
    "# Get model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5888173b-c88f-4a8c-98fa-58ebf4138a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = get_pl_model('unet')\n",
    "model = get_pl_model('edgemap_fused_unet')\n",
    "# model = get_pl_model('fpn')\n",
    "# model = get_pl_model('deeplabv3plus')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d64246-f26b-4b83-b4a7-ce164b6e6cdf",
   "metadata": {},
   "source": [
    "# Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3df61ae-c4f0-4880-91db-91973c7106f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-5069cfcc378648dc\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-5069cfcc378648dc\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1cb21b-9f03-48fa-b1cf-e0097f7806d3",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbb0a44-6657-4941-b96b-6c646c3017bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name  | Type              | Params\n",
      "--------------------------------------------\n",
      "0 | model | EdgemapFusedModel | 24.4 M\n",
      "--------------------------------------------\n",
      "24.4 M    Trainable params\n",
      "0         Non-trainable params\n",
      "24.4 M    Total params\n",
      "97.749    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4413bf23dbc6495da3812004e75d8e12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model=model.train()\n",
    "args.gpus = None # Remove this line if you actually have gpus\n",
    "\n",
    "tb_logger = loggers.TensorBoardLogger(save_dir=\"logs/\")\n",
    "trainer = Trainer(gpus=args.gpus,\n",
    "                  max_epochs=args.epochs, \n",
    "                  logger=tb_logger,\n",
    "                  # accelerator=args.accelerator,\n",
    "                  resume_from_checkpoint=args.checkpoint_path,\n",
    "                  log_every_n_steps=10\n",
    ")\n",
    "trainer.fit(model, train_dataloader, val_dataloader)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fc7cf9-dabd-4ebf-8d71-dd8bc58273fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.model.model.decoder.blocks[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba691c1d-9c12-46a4-9e42-ec461f5c39f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mask_middle=model.model.model(torch.Tensor(img[None,:])).detach().argmin(dim=1).numpy()\n",
    "pred_mask=model.predict(torch.Tensor(img[None,:])).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d23dfeb-bcd8-4435-bf2b-15b4174dd35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "f, axarr = plt.subplots(1,2)\n",
    "_ = axarr[0].imshow(pred_mask_middle.transpose(1,2,0))\n",
    "_ = axarr[1].imshow(pred_mask.transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137860e5-8cf4-4d10-b137-cbf8b32531be",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mask_middle.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a72f2f-5d94-42ee-aedf-6f83fa1ef1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mask.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cb1596-af93-4925-845a-9d965da6f795",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83319a1-3858-4682-b223-b9adfd25ad39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "img, mask = train_dataloader.dataset[4]\n",
    "# fused = model.model.get_fused_input(torch.Tensor(img[None,:]))\n",
    "pred_mask=model.predict(torch.Tensor(img[None,:])).detach().numpy()\n",
    "f, axarr = plt.subplots(1,3)\n",
    "_ = axarr[0].imshow(img.transpose(1,2,0))\n",
    "_ = axarr[1].imshow(mask.transpose(1,2,0))\n",
    "_ = axarr[2].imshow(pred_mask.transpose(1,2,0))\n",
    "# _ = axarr[3].imshow(fused[0,3:,...].numpy().transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849931ad-a43a-4221-a4d8-bd613af288ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from segmentation_models_pytorch.encoders import get_encoder\n",
    "from pytorch_hed.run import estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0d236e-aecb-4ce1-96e3-5b9af4c3281d",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = get_encoder(\n",
    "    'resnet34',\n",
    "    in_channels=1,\n",
    "    # depth=encoder_depth,\n",
    "    weights='imagenet',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08da68a9-8195-4ef3-bc1a-7adbb95253a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "edgemap = estimate(torch.Tensor(img[None,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22bcbc8-9e18-4e28-8434-73e3053288b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "edgemap.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b60fe6e-1b00-4611-8d78-150f602455d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "edgemap = model.model.edgemap_layers(edgemap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcc0cde-638e-40f3-b15f-04734ba24da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.model.model(img)\n",
    "pred_middle_mask=model.model.model(torch.Tensor(img[None,:])).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17c15b0-2b7d-4815-8313-e81dc2d8276c",
   "metadata": {},
   "outputs": [],
   "source": [
    "out=pred_middle_mask+edgemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c8068f-d8a2-4c8e-92ad-ab1814082dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_middle_mask\n",
    "\n",
    "pred_middle_mask = pred_middle_mask.max(dim=1).values\n",
    "plt.imshow(pred_middle_mask.detach().numpy().transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b74f71-8b2f-4df4-a429-956566f43040",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = out.max(dim=1).values\n",
    "plt.imshow(out.detach().numpy().transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0d6466-76d4-4a6d-ab89-8be46bae3fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_middle_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8853faa-519e-4353-a5a9-471b19d0fbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "edgemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2cdffd-59cf-4099-a92e-2957e31112a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "edgemap = edgemap.max(dim=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1555c6-0fef-4630-9145-f35ca4b76505",
   "metadata": {},
   "outputs": [],
   "source": [
    "edgemap=edgemap.detach().numpy()[0][None,:].transpose(1,2,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36f6d5f-70b8-406f-b4a4-ebc52f836f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "edgemap=edgemap.detach().numpy()[0].transpose(1,2,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01d5824-8ef9-4ec6-aa3d-ea624f51d73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(edgemap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c395e8e-dc9c-46a3-bfd9-3ad9221ce93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(edgemap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05b85b3-9e93-4352-aed9-b7b2f17edd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_out = resnet.forward(edgemap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6c4f0d-87d6-4406-9bbf-fcc30b67d604",
   "metadata": {},
   "outputs": [],
   "source": [
    "edgemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab22d7ff-8ac4-4397-bbaf-dbdb867f016d",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_out[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30362bc-94dd-4ab4-8f73-9ad6722a3f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "edgemap_out=resnet_out[2][0][:1].detach().numpy().transpose(1,2,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607edc43-120b-4c26-963a-5a751fbb7e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "edgemap_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52154fd-078d-4d9d-a038-32d3ccfd18f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(edgemap_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a9b2a1-309a-420a-b30f-e1aafdefbc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "edgemap_out.mean(),edgemap.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074adef8-17b6-402b-a75b-3fc4451b798f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
